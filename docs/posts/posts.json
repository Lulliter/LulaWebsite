[
  {
    "path": "posts/2022-06-08-nerderland/",
    "title": "Nerderland",
    "description": "A short description of the post.",
    "author": [
      {
        "name": "Luisa M. Mimmi",
        "url": {}
      }
    ],
    "date": "2022-06-08",
    "categories": [
      "tools"
    ],
    "contents": "\n\nContents\nStart at the kernel\nboh\n\n\n\nArtwork by @allison_horstStart at the kernel\nJeroen Janssens - Set your R code free; turn it into a\ncommand-line tool\n video\nboh\n\n repo html\n\n\n\n\n",
    "preview": {},
    "last_modified": "2022-06-09T15:37:43+02:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-05-28-github-pat/",
    "title": "Github authentication with PAT",
    "description": {},
    "author": [],
    "date": "2022-05-28",
    "categories": [
      "tools"
    ],
    "contents": "\n\nContents\nSetting up GitHub &\nauthentication\nReference / tutorials\nVerify\nyour git installation & configuration (from terminal)\nIf needed,\nintroduce yourself to git (from R)\n\n3 ways to authenticate in\nGithub\n3.1.a How I configured\nGithub PAT\n3.3 What are SSH keys?\nCheck which ssh I already\nhave\nWhich one\nam I currently using for my Github account?\n\n\nSetting up GitHub &\nauthentication\nReference / tutorials\nTutorial on\nR & Github setup!!!\nSetting\nUp a Personal Access Token via R\n\n\n\n\nVerify\nyour git installation & configuration (from terminal)\nsee\ninfo on Atlassian The git config command is a\nconvenience function that is used to set Git configuration values on a\nglobal or local project level. These configuration levels correspond to\n.gitconfig text files.\n\nLEVELS of git config\n\nBy default, git config will write to a local level\nif no configuration option is passed. Local level configuration is\napplied to the context repository git config gets invoked in.\nLocal configuration values are stored in a file that can be found in the\nrepo‚Äôs .git directory: .git/config.\ngit config --local\nGlobal level configuration is user-specific,\nmeaning it is applied to an operating system user. Global\nconfiguration values are stored in a file that is located in a user‚Äôs\nhome directory. ~ /.gitconfig on unix systems and\nC:\\Users\\\\.gitconfig on windows.\ngit config --global\nSystem level System-level configuration is applied\nacross an entire machine. This covers all users on an operating\nsystem and all repos. The system level configuration file lives in\na gitconfig file off the system root path.\n$(prefix)/etc/gitconfig on unix systems.\ngit config --system\n\n# check version\ngit version\n\n\nSince these are hidden files I need ls -al to see\nthem\n\n\n# see hidden config files\ncd ~\nls -al .git*\n\n# or using git command...   \ngit config --list --show-origin\n\n# check configuration \ngit config --list\n\n# among other stuff\n# ...\n# credential.helper=osxkeychain\n# user.name=Lulliter\n# user.email=lmm76@georgetown.edu\n# aliases!!!!! \n\n# ask child property like  \ngit config user.email\n# lmm76@georgetown.edu\n\n# write a child property like  \ngit config --global user.email \"lmm76@georgetown.edu\"\n\nIf needed, introduce\nyourself to git (from R)\n\n\n# {NOT RUN}\n## set your user name and email:\nlibrary(usethis)\n\n# ---STOP!---- not sure this still exists \nif (FALSE) {\n# set the user's global user.name and user.email\nuse_git_config(user.name = \"Lulliter\", user.email = \"lmm76@georgetown.edu\")\n\n# (OR set the user.name and user.email locally, i.e. for current repo/project\nuse_git_config(\n  scope = \"project\",\n  user.name = \"Lulliter\", \n  user.email = \"lmm76@georgetown.edu\"\n)\n}\n\n\n\n3 ways to authenticate in\nGithub\npassword authentication [deprecated since August\n2021]\nPATs (Personal Access Tokens) Authentication [*me, | recommended\nbeginners]\nSSH Key Authentication\nApplications API tokens\n\n‚Äúif you have no burning reason to pick SSH‚Äù (1) is recommended by Jenny\nBryan\n\n3.1.a How I configured Github\nPAT\nClear instructions here,\nand here (JB),\nand here\n(ROpensci).\nA proper PAT is characterized by the following four features:\nUnique: It is distinctive to GitHub and can be\ngenerated per device or usage.\nRevocable: It can be individually revoked at any\ntime without needing to update any credentials.\nLimited: It is narrowly scoped by definition and\nprovides access only to a limited set of operations.\nRandom: Unlike passwords, it is not subject to\ndictionary or brute force attacks.\n\nWith the PAT, I will be performing Git operations over HTTPS protocol\n(as opposed to SSH).\n\n1) Create Github PAT\nEither:\nGo to https://github.com/settings/tokens and click ‚ÄúGenerate\ntoken‚Äù.\nCreate a personal access token for authentication (from R)\nwith:\n\n\nusethis::create_github_token() \n## in case usethis version < 2.0.0: usethis::browse_github_token() \n# (or even better: update usethis!)\n\n\n\n2)\nProvide this PAT next time a Git operation asks for your password\nEither:\nPut the PAT into the Git credential store\nUse gitcreds::gitcreds_set() (from R) ‚Äì> this will\nprompt to paste the PAT\n3) Managing/Verifying\ngit credential stored\n\nWhere do I see it on Github?\n\n‚Äì> settings ‚Äì> Developer\nsettings ‚Äì> Personal Access Tokens\n\n\nWARNING:\ncredentials::git_credential_ask(\"https://github.com\")\nactually exposes the PAT password\n\n\n\ncredentials::credential_helper_get()\n      # [1] \"osxkeychain\"\n\n# to see all of them \ncredentials::git_credential_ask(\"https://github.com\")\n      # $protocol\n      # [1] \"https\"\n      # $host\n      # [1] \"github.com\"\n      # $username\n      # [1] \"PersonalAccessToken\"\n      # $password\n      # [1] \"ghp_...8tNB\" !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n      # attr(,\"class\")\n      # [1] \"git_credential\"\n\n# --- other useful things to check \n#usethis::gh_token_help()\nusethis::git_sitrep()\ngh::gh_whoami()\n# {\n#   \"name\": \"Luisa Mimmi\",\n#   \"login\": \"Lulliter\",\n#   \"html_url\": \"https://github.com/Lulliter\",\n#   \"scopes\": \"gist, repo, user, workflow\",\n#   \"token\": \"ghp_...52eR\"\n# } \n\n\n\n3.3 What are SSH keys?\nSecure Shell Protocol (SSH) is a cryptographic network protocol that\nallows a single computer to connect with a server over the internet\nsecurely. SSH is best used for accessing remote servers.\nCheck which ssh I already\nhave\n\nI have a github SSH but I am not using it yet!\n\n\n ls -al ~/.ssh/   \n\n#  total 40\n# drwx------   7 luisamimmi  staff   224 Sep  8  2017 .\n# drwxr-xr-x@ 99 luisamimmi  staff  3168 May 26 19:50 ..\n# -rw-------@  1 luisamimmi  staff  1766 Jun  6  2015 github_rsa\n# -rw-r--r--   1 luisamimmi  staff   401 Jun  6  2015 github_rsa.pub\n# -rw-------   1 luisamimmi  staff  3243 Feb 21  2018 id_rsa\n# -rw-r--r--@  1 luisamimmi  staff   746 Feb 21  2018 id_rsa.pub\n# -rw-r--r--@  1 luisamimmi  staff  2783 Sep  8  2017 known_hosts\ntotal 40\ndrwx------   7 luisamimmi  staff   224 Sep  8  2017 .\ndrwxr-xr-x@ 99 luisamimmi  staff  3168 Jun  8 11:36 ..\n-rw-------@  1 luisamimmi  staff  1766 Jun  6  2015 github_rsa\n-rw-r--r--   1 luisamimmi  staff   401 Jun  6  2015 github_rsa.pub\n-rw-------   1 luisamimmi  staff  3243 Feb 21  2018 id_rsa\n-rw-r--r--@  1 luisamimmi  staff   746 Feb 21  2018 id_rsa.pub\n-rw-r--r--@  1 luisamimmi  staff  2783 Sep  8  2017 known_hosts\n\nWhich one\nam I currently using for my Github\naccount?\nerrrr NONE!\n\n‚Äì> settings ‚Äì> SSH keys : You\ndon‚Äôt have any public SSH keys in your GitHub account!!!!\nAlthough it does appear to be there as told by\nlibrary(credentials)\n\n\nlibrary(credentials)\n#  Found git version 2.15.1\n# Supported HTTPS credential helpers: cache, cache--daemon, store, osxkeychain\n\n# 'git\n# Found OpenSSH_8.1p1, LibreSSL 2.7.3\n# Default SSH key: /Users/luisamimmi/.ssh/id_rsa\n\n\n\n‚Ä¶tbc\n\n\n\n",
    "preview": {},
    "last_modified": "2022-06-08T11:56:51+02:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-05-10-githubpages-aws/",
    "title": "Github Pages & AWS",
    "description": {},
    "author": [],
    "date": "2022-05-10",
    "categories": [
      "tools"
    ],
    "contents": "\n\nContents\nInstructions\nfor website {Github Pages + AWS}\non GitHub:\ninitiate a repo in the usual way\non AWS: Buy a domain\non GitHub:\ndeploy website via Github Pages\non local: CNAME\non AWS:\nredirect the domain to my website on Github pages\n\nREFERENCE\n\nInstructions for\nwebsite {Github Pages + AWS}\nThe following steps guide through setting up a new website that is\nhosted on GitHub Pagesand - since GitHub Pages supports\nusing custom domains to subsequently re-direct the site‚Äôs URL from the\ndefault <user>.github.io/domain to a custom domain\nname registered on AWS.\nI tested these when setting up/re-directing a toy website for my band\nüé∏ ü•Å üéπ üé§ ‚ÄúThe Padrinoz‚Äù (feel free to check outt the\nrepo with code and\nunofficial site)\non GitHub: initiate\na repo in the usual way\nCreate a new repo on github\nGo on local PARENT directory of the intended repo\nExecute\ngit clone https://github.com/Lulliter/padrinoz_website.git\nalways from the PARENT dir of the REPO run\n library(distill)\n create_website(dir = \"padrinoz_website\",\n title = \"The Padrinoz\",\n gh_pages = TRUE)\nthen you can customize and enrich, but I am not discussing this\nhere‚Ä¶\non AWS: Buy a domain\non AWS: Go to Route53, under ‚Äòregister\ndomain‚Äô then follow instructions to buy a domain (10$ /12$ per\nyear), in my case: thepadrinoz.com.\non AWS_Route53: domain registration should be done\nautomatically\nfirst, it will appear under DOMAINS ‚Äì> Pending Requests [a\nverification email will be sent by AWS]\nafter it will be under DOMAINS ‚Äì> Registered Domains\n\non GitHub: deploy\nwebsite via Github Pages\non Github: Scroll down to the Repo / Setting/ Github Pages section\nclick the drop down menu under ‚ÄúSource‚Äù and click ‚Äúmaster branch‚Äù\non Local: make some adaptation / add content\n(on Terminal/RStudio: Build the site locally\n\n\n\non Terminal/RStudio: git add/commit/push (or see\n./_render-deploy.sh)\non local: CNAME\nLooking forward, we will need to have a file named CNAME\nthat contains a single row: your custom domain (in this case:\nthepadrinoz.com) + create + commit + push\nNOTE: ‚ùó Before adding/committing to repo CNAME, at\nevery push, the custom domain gets decoupled from GH Pages\nsettings‚ùó\non\nAWS: redirect the domain to my website on Github pages\nFollowing blog\nand GITHUB\nLog into AWS Console ‚Äì> Route53\nIn your Route53 dashboard, click hosted\nzones\n\nClick Click the domain you would like to use\n\nClick Create Record (This will be your yourdomain.com rule)\nDo not enter anything into the Name field\nUnder the Type dropdown, select A ‚Äî IPv4 addresses\nThe Alias toggle should be UNSELECTED\nEnter the following four IP addresses into the value text area.\n\n185.199.108.153\n185.199.109.153\n185.199.110.153\n185.199.111.153\nThen click Save Record Set ‚ÄúCreate Record‚Äù .\n\nThird, create another A type of record set. And this will be your\nwww.yourdomain.com rule. And it will be an alias for yourdomain.com.\nClick Create Record Set, again\nInto the Name field, enter ‚Äòwww‚Äô\nUnder the Type dropdown, select A ‚Äî IPv4 addresses, again\nSELECT Alias on the dashboard, from dropdown menu, choose\n‚ÄúAlias to another record in this hosted zone‚Äù and then\n‚Äúyourdomain.com.‚Äù (it has the full stop!?!)\nThen click Save Record Set ‚ÄúCreate Record‚Äù .\n\n\nLast, go back to Github repository‚Äôs settings tab\nScroll down to the GitHub Pages section\nIn the Custom domain field enter your custom domain:\nyour-custom-domain.com\nClick Save\nCheck Enforce HTTPS\n\nLastest, go to ‚Äú_site.yml‚Äù and replace\nbase_url\nname: \"padrinoz_website\"\ntitle: \"The Padrinoz\"\nbase_url: https://thepadrinoz.com\nfix GHPages error asking me to point www.domain.com to a CNAME\nrecord (instead of an A record)\n\nREFERENCE\ngitGitHub\ninstructions\nYeongho\nKim‚Äôs tutorial to set up a AWS Route 53 custom domain\nBen\nWiz‚Äôs guide to deploy GitHub pages‚Äô site with AWS Route 53\nSai\nChandu Bobbili‚Äôs guide\n\n\n\n",
    "preview": {},
    "last_modified": "2022-05-10T16:04:20+02:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-04-25-r-working-with-lists/",
    "title": "R - working with lists",
    "description": {},
    "author": [],
    "date": "2022-04-25",
    "categories": [
      "tools"
    ],
    "contents": "\n\nContents\nTheory Key Sources\n[CASE\n1] S.O. problem ‚Äúnested-list-to-wide-dataframe‚Äù\nIndexing Lists\nNesting/Unnesting Lists\nStarting from 1\nelement/observation only ‚Ä¶\n‚Ä¶ then ALL\nelements (faster) - {do.call}{rbind}\n‚Ä¶ then ALL\nelements (clunkier, but clearer) - {tidyr}\n‚Ä¶ then\nALL elements (not convinced) - {data.table}{purrr}\n\n\n[CASE 2] RStudio\nprob. list of lists to df\n-\nDifferent ways to transform list of lists into df\n\n[CASE\n3] RStudio prob. list of lists (of lists) to df\n-\nDifferent ways to transform list of lists (of lists) into df\n\n\nTheory Key Sources\nJenny Bryan‚Äôs STAT545\ncourse\nVincenzo Coia‚ÄôsSTAT545\ncourse - new version\nTidyr\nBlog\nCapter\n9 Introduction to Programming with R\n[CASE 1] S.O.\nproblem ‚Äúnested-list-to-wide-dataframe‚Äù\nTrying to answer to SO questions: https://stackoverflow.com/questions/51020513/r-nested-list-to-wide-dataframe\n\n\n# Very nested example taken from stackoverflow.com  \nx <- list()\nx[[1]] <- list(uuid = \"123\",\n               relationships = list(websites = list(items =  list(\n                 properties.website_type = c(\"homepage\", \"facebook\", \"twitter\", \n                                             \"linkedin\"),\n                 properties.url = c(\"www.example1.com\", \"www.fbex1.com\", \n                                    \"www.twitterex1.com\", \"www.linkedinex1.com\")))))\nx[[2]] <- list(uuid = \"987\",\n               relationships = list(websites = list(items =  list(\n                 properties.website_type = c(\"homepage\",\"facebook\",\"twitter\"),\n                 properties.url = c(\"www.example2.com\", \"www.fbex2.com\", \n                                    \"www.twitterex2.com\")))))\n str(x)\n\n\n#> List of 2\n#>  $ :List of 2\n#>   ..$ uuid         : chr \"123\"\n#>   ..$ relationships:List of 1\n#>   .. ..$ websites:List of 1\n#>   .. .. ..$ items:List of 2\n#>   .. .. .. ..$ properties.website_type: chr [1:4] \"homepage\" \"facebook\" \"twitter\" \"linkedin\"\n#>   .. .. .. ..$ properties.url         : chr [1:4] \"www.example1.com\" \"www.fbex1.com\" \"www.twitterex1.com\" \"www.linkedinex1.com\"\n#>  $ :List of 2\n#>   ..$ uuid         : chr \"987\"\n#>   ..$ relationships:List of 1\n#>   .. ..$ websites:List of 1\n#>   .. .. ..$ items:List of 2\n#>   .. .. .. ..$ properties.website_type: chr [1:3] \"homepage\" \"facebook\" \"twitter\"\n#>   .. .. .. ..$ properties.url         : chr [1:3] \"www.example2.com\" \"www.fbex2.com\" \"www.twitterex2.com\"\n\nIndexing Lists\nLists can be subset according to their index,\nname or logical statement\n\n\n# Structure\n# list x = [id1 id2   ]\n#     list id1 = [uuid, rel_l,] \n#         list rel = [web_l]   \n#                 list web = [items_l]          \n#                    list items = [char, char ]              \n\nstr(x)    \nlength(x) # 2\nmode(x)\nclass(x)\n\n# Indexing\n# name the lists\nnames(x)\nnames(x) <- c(\"id1\", \"id2\")\nnames(x)\n\n# [ desired return value is 1st element AS a list  (keeps the box)\nx1_l <- x[1]\nstr(x1_l)\n# [[ | $ desired return value is 1st element AS element !!! (out of the box)\nx1_e <- x$id1 # qui sono scesa di 1 livello!!!!\nstr(x1_e)\nx1_e <- x[[1]] # qui sono scesa di 1 livello!!!!\nstr(x1_e)\n\n# If you wanted to get the CONTENT of the 1st element\nx1_e_1 <- x[[1]][[1]]\nstr(x1_e_1) # char \"123\"\n\nx[\"id2\"]\nstr(x[\"id2\"]) # list of 1 \n\n# indexing > 1 element (AS LISTS)\nx[c(\"id1\",\"id2\")]       # List of 2\nstr(x[c(\"id1\",\"id2\")]) # list \n\n\n\nNesting/Unnesting Lists\nStarting from 1\nelement/observation only ‚Ä¶\n\n\n# -- OPPURE --- step by step \n\n# get the CONTENT inside the 2nd Variable of the 1st element\nx1_e_2 <-x[[1]][[2]]\nstr(x1_e_2) \n# list \n# $websites\n# $websites$items\n# $websites$items$properties.website_type\n# [1] \"homepage\" \"facebook\" \"twitter\"  \"linkedin\"\n# \n# $websites$items$properties.url\n# [1]\"www.example1.com\"\"www.fbex1.com\"\"www.twitterex1.com\"\"www.linkedinex1.com\"\n\n# Make this a tibble with a list in one column  \"websites\"\nx1_e_2_t <- as_tibble(x1_e_2)\nstr(x1_e_2_t) # tibble [1 √ó 1l-l]\n# Unnest wider the column --> 2 cols:'properties.website_type' 'properties.url'\nx1_e_2_t <- x1_e_2_t %>% \n  tidyr::unnest_wider( col = \"websites\")\nx1_e_2_t #  tibble: 1 √ó 2(l)\n# Unnestlonger the column \n# --> 4 rows/each col:\"homepage\"\"facebook\"\"twitter\"\"linkedin\"\nx1_e_2_t <- x1_e_2_t %>% \n  tidyr::unnest_longer(data =. , col = c(\"properties.website_type\",\n                                         \"properties.url\"  ))\nx1_e_2_t # -->  tibble: 4 √ó 2 \n\n# -- OPPURE --- all in one \n# turn first level list into a tibble of 1 col (which is a list of lists)\nx1_e_2_t <- as_tibble(x1_e_2) %>%                   # -->  tibble [1 √ó 1l-l]\n  # split in two cols \n  tidyr::unnest_wider(data =., col = \"websites\") %>% # -->  tibble: 1 √ó 2(l)\n  # split in 4 rows \n  tidyr::unnest_longer(data =., col = c(\"properties.website_type\",\n                                        \"properties.url\")) # -->  tibble: 4 √ó 2 \nstr(x1_e_2_t)\n\n\n\n‚Ä¶ then ALL elements\n(faster) - {do.call}{rbind}\n\n\n#convert list to dataframe in long format\nx_df <- do.call(rbind, lapply(x, data.frame, stringsAsFactors = FALSE))\nx_df # 7 x 3\n\n\n#>       uuid relationships.websites.items.properties.website_type\n#> id1.1  123                                             homepage\n#> id1.2  123                                             facebook\n#> id1.3  123                                              twitter\n#> id1.4  123                                             linkedin\n#> id2.1  987                                             homepage\n#> id2.2  987                                             facebook\n#> id2.3  987                                              twitter\n#>       relationships.websites.items.properties.url\n#> id1.1                            www.example1.com\n#> id1.2                               www.fbex1.com\n#> id1.3                          www.twitterex1.com\n#> id1.4                         www.linkedinex1.com\n#> id2.1                            www.example2.com\n#> id2.2                               www.fbex2.com\n#> id2.3                          www.twitterex2.com\n\n#final result\nx_df_spread <- x_df %>%\n  spread(relationships.websites.items.properties.website_type, relationships.websites.items.properties.url)\nx_df_spread # 2 x 5 \n\n\n#>   uuid      facebook         homepage            linkedin\n#> 1  123 www.fbex1.com www.example1.com www.linkedinex1.com\n#> 2  987 www.fbex2.com www.example2.com                <NA>\n#>              twitter\n#> 1 www.twitterex1.com\n#> 2 www.twitterex2.com\n\n‚Ä¶ then ALL\nelements (clunkier, but clearer) - {tidyr}\n\n\nnames(x) <- c(\"id1\", \"id2\")\nview(x)\n\n# in steps \n# x_df <- x %>% as_tibble_col( .)  \n# str(x_df)\n# x_df <- x_df %>% unnest_wider(col = \"value\") # 1\n# str(x_df)\n# x_df <- x_df %>% unnest_longer(col = \"relationships\")  # 2\n# str(x_df)\n# x_df <- x_df %>% unnest_wider(col = \"relationships\") # 2\n# str(x_df)\n# x_df <- x_df %>% unnest_wider(col =  \"items\") # 2\n# str(x_df)\n# x_df <- x_df %>% \n# unnest_longer(col = c(\"properties.website_type\", \"properties.url\"))\n# str(x_df)\n\n# --- Iterations of unnest:\nx_df2 <- x %>% tibble::as_tibble_col( .) %>%  \n  tidyr::unnest_wider(col =\"value\")  %>% \n  tidyr::unnest_longer(col =\"relationships\")   %>%  \n  tidyr::unnest_wider(col = \"relationships\")  %>%  # not sure why? twice ?!?!\n  tidyr::unnest_wider(col = \"items\")  %>%  \n  tidyr::unnest_longer(col = c(\"properties.website_type\", \n                               \"properties.url\")) %>% \n  # --- Lastly, group by id: \n  group_by(uuid) %>% \n  tidyr::pivot_wider(data = ., \n                     names_from = properties.website_type, \n                     values_from = c(\"properties.url\"))\n\nx_df2\n\n\n#> # A tibble: 2 √ó 6\n#> # Groups:   uuid [2]\n#>   uuid  relationships_id homepage         facebook    twitter linkedin\n#>   <chr> <chr>            <chr>            <chr>       <chr>   <chr>   \n#> 1 123   websites         www.example1.com www.fbex1.‚Ä¶ www.tw‚Ä¶ www.lin‚Ä¶\n#> 2 987   websites         www.example2.com www.fbex2.‚Ä¶ www.tw‚Ä¶ <NA>\n\n‚Ä¶ then ALL\nelements (not convinced) - {data.table}{purrr}\n\n\n# starting point \nstr(x$id1)        # 2nd level list is a  `list`  \n\ndt_list <- purrr::map(x, as.data.table)\nstr(dt_list$id1) # 2nd level list is a  `data.table`  !!! \n\ndt <- rbindlist(dt_list, use.names =  T, fill = TRUE, idcol = F) # 2nd COLUMN is of lists  \n#   uuid relationships\n# 1:  123     <list[1]>\n# 2:  987     <list[1]>\n\ndt_df <- data.frame(matrix(unlist(dt), nrow=length(dt), byrow=F)) # but lost names of vars \n\n\n\n[CASE 2] RStudio prob.\nlist of lists to df\nRStudio\nresponse\n\n\n# 1 list of 2 lists (3 & 2 obs each)\nnested_l <- list(\n  list( id = \"a\", values = c(1, 2, 3) )\n  , list( id = \"b\", values = c(78, 99) )\n)\n\nstr(nested_l)\n\n\n#> List of 2\n#>  $ :List of 2\n#>   ..$ id    : chr \"a\"\n#>   ..$ values: num [1:3] 1 2 3\n#>  $ :List of 2\n#>   ..$ id    : chr \"b\"\n#>   ..$ values: num [1:2] 78 99\n\n- Different\nways to transform list of lists into df\n\n\n# 1) TRANSFORM TO DF WITH COLUMN-list\n#  2x2  (1 column is a list )\ndf_l <- as.data.frame(do.call( rbind, nested_l))\ndf_l\n\n\n#>   id  values\n#> 1  a 1, 2, 3\n#> 2  b  78, 99\n\n# 2.a) TRANSFORM TO DF WITH COLUMN-vector\n#  5 obs x2  (1 column is a list )\ndf <- tidyr::unnest(data = as.data.frame(do.call(rbind, nested_l)), \n                    cols = values)\ndf\n\n\n#> # A tibble: 5 √ó 2\n#>   id        values\n#>   <list>     <dbl>\n#> 1 <chr [1]>      1\n#> 2 <chr [1]>      2\n#> 3 <chr [1]>      3\n#> 4 <chr [1]>     78\n#> 5 <chr [1]>     99\n\n# 2.b) TRANSFORM TO DF WITH COLUMN-vector\n#  5 obs x2  (1 column is a list )\n# `map_dfr` return a data frame created by row-binding (`map_dfc` column-binding)\ndf_purr <- purrr::map_dfr(.x = nested_l,\n                          ~ tidyr::unnest(data.frame(.),\n                                          cols = c(\"id\", \"values\")))\ndf_purr\n\n\n#> # A tibble: 5 √ó 2\n#>   id    values\n#>   <chr>  <dbl>\n#> 1 a          1\n#> 2 a          2\n#> 3 a          3\n#> 4 b         78\n#> 5 b         99\n\n# 2.c) TRANSFORM TO DF WITH COLUMN-vector\n# actually no need to unnest\ndf_purr2 <- purrr::map_dfr(.x = nested_l,\n                           ~. )\ndf_purr2\n\n\n#> # A tibble: 5 √ó 2\n#>   id    values\n#>   <chr>  <dbl>\n#> 1 a          1\n#> 2 a          2\n#> 3 a          3\n#> 4 b         78\n#> 5 b         99\n\n[CASE 3]\nRStudio prob. list of lists (of lists) to df\n\n\n# HARDER ------------------------------------------------------------------\n# A distinct analysis.\nlevel3.list1 <- list(\n  key1 = \"name 1\"\n  , key2 = 14\n  , key3 = 15\n  , key4 = c(15, 29, 43, 57)\n  , key5 = 332\n  , key6 = c(\"A\", \"B\", \"C\")\n)\n\nlevel3.list2 <- list(\n  key1 = \"name 2\"\n  , key2 = 28\n  , key3 = 15\n  , key4 = c(15, 43, 71, 99)\n  , key5 = 332\n  , key6 = c(\"Y\", \"Z\")\n)\n\nlevel3.list3 <- list(\n  key1 = \"name 3\"\n  , key2 = 56\n  , key3 = 22\n  , key4 = c(78, 134, 190, 246)\n  , key5 = 112\n  , key6 = c(\"V\")\n)\n\n# Grouped analyses.\nlevel2.list1 <- list( level3.list1, level3.list2 )\nlevel2.list2 <- list( level3.list3 )\n\n# Planned samplings.\nlevel1.list1 <- list(\n  code = \"ABC123\"\n  , type = \"spot\"\n  , matrix = \"water\"\n  , analyses = level2.list1\n)\n\nlevel1.list2 <- list(\n  code = \"GHS332\"\n  , type = \"mix\"\n  , matrix = \"water\"\n  , analyses = level2.list2\n)\n\n# All the samplings.\nlevel0.list <- list(level1.list1, level1.list2)\n\nstr(level0.list)\n\n\n#> List of 2\n#>  $ :List of 4\n#>   ..$ code    : chr \"ABC123\"\n#>   ..$ type    : chr \"spot\"\n#>   ..$ matrix  : chr \"water\"\n#>   ..$ analyses:List of 2\n#>   .. ..$ :List of 6\n#>   .. .. ..$ key1: chr \"name 1\"\n#>   .. .. ..$ key2: num 14\n#>   .. .. ..$ key3: num 15\n#>   .. .. ..$ key4: num [1:4] 15 29 43 57\n#>   .. .. ..$ key5: num 332\n#>   .. .. ..$ key6: chr [1:3] \"A\" \"B\" \"C\"\n#>   .. ..$ :List of 6\n#>   .. .. ..$ key1: chr \"name 2\"\n#>   .. .. ..$ key2: num 28\n#>   .. .. ..$ key3: num 15\n#>   .. .. ..$ key4: num [1:4] 15 43 71 99\n#>   .. .. ..$ key5: num 332\n#>   .. .. ..$ key6: chr [1:2] \"Y\" \"Z\"\n#>  $ :List of 4\n#>   ..$ code    : chr \"GHS332\"\n#>   ..$ type    : chr \"mix\"\n#>   ..$ matrix  : chr \"water\"\n#>   ..$ analyses:List of 1\n#>   .. ..$ :List of 6\n#>   .. .. ..$ key1: chr \"name 3\"\n#>   .. .. ..$ key2: num 56\n#>   .. .. ..$ key3: num 22\n#>   .. .. ..$ key4: num [1:4] 78 134 190 246\n#>   .. .. ..$ key5: num 112\n#>   .. .. ..$ key6: chr \"V\"\n\n-\nDifferent ways to transform list of lists (of lists) into df\nUsing purrr::map_dfr returns a data frame created by\nrow-binding (last column is of lists)\n\n\n# \"Flattening\" \n# 3x4 [l]\ndf_l.lev2 <- purrr::map_dfr(level0.list, ~.)\n\n\n\nUsing tibble + unnest_... returns a data\nframe only of atomic vectors\n\n\n# 1) Step by step \nu1 <- level0.list %>% tibble() %>%\n  unnest_wider(col = \".\")\nu2 <- u1 %>% unnest_longer(col = \"analyses\")\nu3 <- u2 %>% unnest_wider(col = \"analyses\")\nu4 <- u3 %>% unnest_longer(col = \"key4\")\nu5 <- u4 %>% unnest_longer(col = \"key6\")\n\n# 2) All in one with piping\nu <- tibble(level0.list) %>%\n  # integers are just a quick way to select the columns to operate on\n  unnest_wider(1)   %>%  # u1\n  unnest_longer(4)  %>% # u2\n  unnest_wider(4)   %>%  # u3\n  unnest_longer(7)  %>% # u4\n  unnest_longer(9)     # u  24 obs X 9 var\n\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2022-05-12T12:26:30+02:00",
    "input_file": {}
  },
  {
    "path": "posts/2019-09-29-r-stuff/",
    "title": "Useful R stuff",
    "description": {},
    "author": [],
    "date": "2019-09-29",
    "categories": [
      "tools"
    ],
    "contents": "\n\n\n\n\nHere are some useful links and resources for R programming.\nR from TERMINAL &\nAUTOMATION\nVarious resources from the course STAT545\nShaun\nJackman and Jenny Bryan‚Äôs automation notes for getting familiar with\nthe command line.\nGreat post Using\nrstudio-terminal/\nMore on Using\nthe RStudio Terminal\nWorking with strings, regex\nGreat post How to\nwork with strings in base R‚Ä¶\nGeneral\nRstudio Community:\nforum and discussions organized by macro-topic.\nRseek: a sort of wiki R page!\nFrom\nrstudioconf2019: a collection of R resources by @littlemissdata\nCheatsheets:\nself-explanatory\nWTF.. or ‚ÄúWhat They\nForgot to Teach You About R‚Äù :wink: Another life-changing guide\nfrom Jenny Bryan\nGoogle‚Äôs R\nStyle Guide\nProject Management\nBest Practices Handling\nPackages\nR-Bloggers\nblog (scroll to) reference: collection of links‚Ä¶\nanalytical work\nreproducibly using R: Pre-print article\nKarl\nBroman slides\nJoris Muller‚Äôs Blog on The\n‚Äúten simple rules for reproducible computational research‚Äù in R\nJoris Muller‚Äôs Blog on A\nbasic reproducible data analysis workflow - principles\nDATABASES in R\nDatabases using R RStudio\nlist\nAPI & R\nAmanda Gadrow Resources\nSaving tokens Various\nWays\nSaving tokens WTF‚Ä¶ to tell\nyou\nggplot2 & GRAPHS\nGreat line by line tutorial ggplot\nflipbook\nModern Dive Chapter Grammar of\nGraphics\nTable Packages to discover\nDataExplorer EDA, See github\nFormattable Tables, See more\ninfo\ntable1 Tables, See more\ninfo\nggstatsplot Graphs, See more info\nExtension of ggplot2 package for creating graphics with details from\nstatistical tests included in the plots themselves and targeted\nprimarily at behavioral sciences community.\nSilly\nEMOJI CHEAT\nSHEET: for adding :gem:, :sparkles:, :cool: in markdown\n\n\n\n",
    "preview": {},
    "last_modified": "2022-06-08T10:58:07+02:00",
    "input_file": {}
  },
  {
    "path": "posts/2018-09-28-dirs-files/",
    "title": "Working with directories and lists of files",
    "description": "A short description of the post.",
    "author": [],
    "date": "2018-09-28",
    "categories": [
      "tools"
    ],
    "contents": "\n\nContents\n1)\nUsing {base}dir + {base}load(wrapped in\n{base}lapply) to LOAD several files\n2)\nSelectively load the list of FILES ending with ‚Äú‚Äù\n3)\nNow, a variation on the theme from tidyverse package purrr\nto EXECUTE several R scripts\n\n\n\nif (!require(pacman)){install.packages('pacman')}\np_load(tidyverse)\n\n\n\nA few useful R code chunks to execute common tasks when I compile a\ncomplex research project with several sub-folders organizing the\ncontent. A very common goal is to load in the environment all the files\nstored in a certain sub-directory of the project.\n1)\nUsing {base}dir + {base}load(wrapped in\n{base}lapply) to LOAD several files\nFor example base::dir produces a character vector of the\nnames of files or directories in the named dir:\n\ndir(path = \".\", pattern = NULL, all.files = FALSE,full.names = FALSE, recursive = FALSE, > ignore.case = FALSE, include.dirs = FALSE, no.. = FALSE)\n\n‚Ä¶ and I can use it to obtain a list of files which I then\nbase::readRDS using base::lapply:\n\n\n# Get the list of FILES \nfile_names  <-  as.list(dir(\n  path =\"./_posts/2018-09-28-dirs-files/files\", # no final {/}\n  pattern = \"*.Rds\",\n  full.names = TRUE ))\nfile_names\n\n\nlist()\n\n# read them in the environment\nlapply( file_names, readRDS  )\n\n\nlist()\n\n2) Selectively\nload the list of FILES ending with ‚Äú‚Äù\nSimilarly, I can use base::list.files, with the addition\nof the argument pattern = <some regex> to screen\ncertain files‚Ä¶ again followed by base::lapply(load)\n\nlist.files(path = \".\", pattern = NULL, all.files = FALSE, full.names = FALSE, recursive = FALSE, ignore.case = FALSE, include.dirs = FALSE, no.. = FALSE)\n\n\n\n# List of files ending with <.Rds>\nfile_names2 <- list.files(path = \"./_posts/2018-09-28-dirs-files/files\",\n               pattern = \".Rds$\",\n                      full.names = T # \"xx$\" = \"ends with  xx\"\n                      # all.files = FALSE,\n                      # full.names = FALSE, recursive = FALSE,\n                      # ignore.case = FALSE, include.dirs = FALSE, no.. = FALSE)\n                      )   \n# read them in the environment\nlapply( file_names2, readRDS  )\n\n\nlist()\n\n3)\nNow, a variation on the theme from tidyverse package purrr\nto EXECUTE several R scripts\nAgain, I use base::list.files, but combined with\npurrr::walk(source) - which is a more sophisticated\nfunction to loop through things and execute something.\nPlus, instead of load I use source because\nI intend to EXECUTE several R scripts contained in a project‚Äôs sub\nfolder.\n\n(*) function purrr:walk is specifically used for\nfunctions that don‚Äôt produce an output (as opposed to\npurrr:map)\n\n\n\n# Get the list of R SCRIPTS [!!!]\nfile_names3 <- list.files(\n  path = \"./_posts/2018-09-28-dirs-files/files\",\n  pattern = \".R$\",\n  all.files = FALSE,  # def (= only visible)\n  full.names = TRUE,  # I NEED dir name prepended\n  recursive = FALSE,  # def  (= no inside sub-dir )\n  ignore.case = TRUE, # (= pattern-matching be case-insensitive)\n  include.dirs = FALSE, # def (subdirectory names NOT be included in recursive listings)\n  no.. = FALSE) %>% # def (both \".\" and \"..\" be excluded also from non-recursive listings) \n  sort(decreasing = FALSE\n      )  \nfile_names3\n\n\ncharacter(0)\n\n# Execute them them in the environment\npurrr::walk(.x = file_names3,\n        .f = source, \n        local = FALSE, \n        echo = TRUE, \n        verbose = TRUE) \n\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2022-05-13T22:38:17+02:00",
    "input_file": {}
  },
  {
    "path": "posts/2018-09-28-dirs-files2/",
    "title": "Working with directories and lists of files 2 (.csv)",
    "description": {},
    "author": [],
    "date": "2018-09-28",
    "categories": [
      "tools"
    ],
    "contents": "\n\nContents\nSome prep first\nLoad\nsome pre-loaded R datasets & save as dataframes\nPreliminary\nparameters setting (2 ways to name elements of list)\n\nCreate post directories\nOption (1) Using a For\nloop\nOption (2) Using\nlapply (within a function)\nOption (3)\nalternative WITH purrr:map walk\nOption(4) alternative\nWITH purrr::map\nOption\n(5) Adjacent topic: drop NA, split, remove duplicates, write to\ndisk\n\nGOAL: A frequent situation I encounter is when I\nhave a number of dataframes (resulting from some analysis) in my\nenvironment and want to convert in .csv files to save or share - while\nretaining the same name(s). Below are a few different ways to do it.\nSome prep first\nLoad some\npre-loaded R datasets & save as dataframes\n\n\n# Explore R default datasets\n# data() \n\n# I save them as DFs in my env\nmtcars <- as.data.frame(mtcars)\niris <- as.data.frame(iris)\norange <- as.data.frame(Orange)\ntitanic <- as.data.frame(Titanic)\nOrange <- as.data.frame(Orange)\nOrchardSprays <- as.data.frame(OrchardSprays)\nairquality <- as.data.frame(airquality)\nairmiles <- as.data.frame(airmiles)\n\n\n\nPreliminary\nparameters setting (2 ways to name elements of list)\n\n\n### 1.a) Create a list of n data frames\nlist_dfs <- list(mtcars, iris ,  orange, titanic)\nlist_dfs[1]\n\n### 1.b) Give names the data frames\nnames(list_dfs) <- c(\"mtcars\",\"iris\", \"orange\" , \"titanic\") \n\n### 2) Create a list of n data frames & GIVE thema  name \nlist_dfs_N <- list(mtcars = mtcars, iris = iris,\n             orange = orange, titanic = titanic ) \nlist_dfs_N[[1]] \n\n\n\nCreate post directories\n\n\n# Create Output Dir... remember final\"/\"\nOutdf2csv <-  file.path(\".\", \"_posts\",\"2018-09-28-dirs-files2\", \"df2csv/\")\ndir.create(Outdf2csv)\n\n# Dir_pcr <-  file.path(\".\", \"_posts\",\"2018-09-28-dirs-files2\",\"pcr/\")\n# dir.create(Dir_pcr)\n\n\n\nOption (1) Using a For loop\nNOTE length(list_loop_DF) # = to the\nlength of the list -> WRONG! (I need apply to all elements)\nseq_along(list_loop_DF) # generates a sequence long as the\nlist -> OK!\n\n\n# Create a list of NAMED dataframes\nlist_loop_DF <- list(airquality = airquality, airmiles = airmiles) \n\n# Write a .csv file with each \nfor (i in seq_along(list_loop_DF)) { # generate a sequence along with \n  # returns list of same length as x \n  \n  # Outdf2csv <- if (!dir.exists(\"./zzz_purrr/Output/\")){\n  # dir.create(file.path(\"./zzz_purrr/Output/\"))\n  #}\n  # else {print(\"Dir already exists!\")}\n  write.csv(x = list_loop_DF[[i]], \n         file = paste0(Outdf2csv, names(list_loop_DF[i]) , \".csv\")  )\n  \n  # OutDir <- if (!dir.exists(\"./zzz_purrr/Output/\")){\n  # dir.create(file.path(\"./zzz_purrr/Output/\"))\n  # }\n  # else {print(\"Dir already exists!\")}\n  write.csv(x = list_loop_DF[[i]], \n         file = paste0(Outdf2csv, names(list_loop_DF[i]) , \".csv\")  )\n  \n}\n\n\n\nOption (2) Using lapply\n(within a function)\nIn simple form, this is what I am going to do:\n`MyFunc <- function (list, OutputDir) { `\n`   OutputDir <- ..set dir location.`\n`   lapply(X = forall(list), FUN, ...)`\n`   }`\n\n\n# Create a list of NAMED dataframes\nlist_lapply_DF <- list(mtcars = mtcars, titanic = titanic ) # \n\n# Output... remember final\"/\"\n# Outdf2csv <-  file.path(\".\", \"content\",\"post\", \"df2csv/\")\n# dir.create(Outdf2csv)\n\n# Write the function with arguments (DFlist, OutputDir)\nFunc_list_lapply <- function(list_lapply_DF) { # optional arg2 (Outdf2csv)\n  # Outdf2csv <- if (!dir.exists(\"./zzz_purrr/Output/\")){\n  # dir.create(file.path(\"./zzz_purrr/Output/\"))\n  # }\n  # else {print(\"Dir already exists!\")}\n  lapply(1:length(list_lapply_DF), # from 1 to n = lenght of \"x\" \n       function(i) write.csv(list_lapply_DF[[i]], # after applying a \"function\"\n                      file = paste0(Outdf2csv,\n                                names(list_lapply_DF[i]),\n                                \".csv\"),\n                      row.names = FALSE))\n}\n\n# Call the function\nFunc_list_lapply(list_lapply_DF)\n\n\n\nOption (3) alternative\nWITH purrr:map walk\nUseful\nlink\nNOTE Writing a file to a disk is considered to be a\nside-effect: we are not interested in changing our data, so should use\nwalk instead of map.\nUsing walk2(.x, .y, .f, ... where .x and\n.y are vectors of the same length .f is a\n2-argument function\n\n\n# Create a list of NAMED dataframes\nlist_purrr_DF <- list(Orange = Orange, OrchardSprays = OrchardSprays ) # \n\n# Set the Output Dir to an object \n\n# Outdf2csv <-  file.path(\".\", \"content\",\"post\", \"df2csv/\")\n# dir.create(Outdf2csv)\n\npath <- file.path(paste0(Outdf2csv, names(list_purrr_DF), \".csv\"))\nwalk2(list_purrr_DF, path, write.csv)\n\n\n\nOption(4) alternative WITH\npurrr::map\nIntructions\nfound in I need to get back to this ‚Ä¶\n\n\n# Data\n# unzip(zipfile = \"pcr.zip\", exdir = \"./content/post/pcr\") \n# will create a data/pcr subfolder and extract the files\npcr_files <- list.files(\n  file.path(\"_posts\",\"2018-09-28-dirs-files2\",\"pcr\"), full.names = TRUE)\n\n#=== map() will name each output element asin the input vector. \nlist.files(file.path(\n  \"_posts\",\"2018-09-28-dirs-files2\",\"pcr\"), full.names = TRUE) %>%\n  set_names() %>% # Use set_names() to keep this information.\n  map(read_delim, delim = \" \") %>% \n  names()\n\n#=== remove the path and extension from the filename using basename() and tools::file_path_sans_ext()\nlist.files(file.path(\"_posts\",\"2018-09-28-dirs-files2\", \"pcr\"),\n        full.names = TRUE) %>%\n  set_names(nm = (basename(.) %>% # remove PATH\n               tools::file_path_sans_ext())) %>% # remove .ext\n  map(read_delim, delim = \" \") %>% \n  names()\n\n# Getting a single tibble out of all files would be much handier.---> map_df\nlist.files(file.path(\n  \"_posts\",\"2018-09-28-dirs-files2\", \"pcr\"), full.names = TRUE) %>%\n  set_names(nm = (basename(.) %>% # remove PATH\n               tools::file_path_sans_ext())) %>% # remove .ext\n  map_df(read_delim, delim = \" \", .id = \"filename\")\n\n# ====Rearrange the data and save multiple files\ndir.create(file.path(\n  \"_posts\",\"2018-09-28-dirs-files2\", \"by_gene\"), showWarnings = FALSE) \n\n# Method 1: using walk2 but inside a mutate call\nlist.files(file.path(\n  \"_posts\",\"2018-09-28-dirs-files2\", \"pcr\"), full.names = TRUE) %>%\n  set_names(nm = (basename(.) %>% tools::file_path_sans_ext())) %>%\n  map_df(read_delim, delim = \" \", .id = \"filename\") %>%\n  group_by(gene) %>%\n  nest() %>%\n  mutate(file_out = paste0(gene, \".csv\"),\n       file_out_path = file.path(\n         \"_posts\",\"2018-09-28-dirs-files2\",  \"by_gene\", file_out),\n       data = walk2(data, file_out_path, write_csv))\n\n# Method 2: using walk on the transposed tibble with an anonymous function\nlist.files(file.path(\n  \"_posts\",\"2018-09-28-dirs-files2\", \"pcr\"), full.names = TRUE) %>%\n  set_names(nm = (basename(.) %>% tools::file_path_sans_ext())) %>%\n  map_df(read_delim, delim = \" \", .id = \"filename\") %>%\n  group_by(gene) %>%\n  nest() %>%\n  mutate(file_out = paste0(gene, \".csv\"),\n       file_out_path = file.path(\n         \"_posts\",\"2018-09-28-dirs-files2\",  \"by_gene\", file_out)) %>%\n  transpose() %>%\n  walk(~write_csv(.$data, .$file_out_path))\n\n\n\nOption\n(5) Adjacent topic: drop NA, split, remove duplicates, write to\ndisk\nIn this case, the five new files (one for each bat family) will end\nup in the working directory, but if we want to do this with more files\nand dedicated directories then using the here and glue packages is\nprobably a good idea. Useful\nlink\n\n\n# read csv from web\nbatRecs <- utils::read.csv(\n  \"https://raw.githubusercontent.com/luisDVA/codeluis/master/batRecords.csv\",\n                  stringsAsFactors = FALSE)\n\n# drop na, split, remove duplicates, write to disk\nbatRecs %>%  na.omit() %>% \n  # split to create a list of data frames for each group, \n  split(.$family) %>% \n  # then map to apply functions to each list element. I\n  map(~distinct(.x,\n            decimal_latitude,\n            decimal_longitude,\n            .keep_all=TRUE)) %>% \n  # walk because write.csv returns nothing and creates the csv file as a side effect\n  walk(~.x %>% write.csv(file = paste0(Outdf2csv, \"nov1_\", unique(.x$family),\n                           \".csv\"),\n                  row.names = FALSE)  \n  )\n\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2022-05-13T23:05:01+02:00",
    "input_file": {}
  },
  {
    "path": "posts/2016-11-15-ramani-huria/",
    "title": "Open spatial data for resilience in Tanzania: Lessons learned from 'Dar Ramani Huria'",
    "description": {},
    "author": [],
    "date": "2016-11-15",
    "categories": [
      "ideas"
    ],
    "contents": "\n\nContents\nCommunity Mapping For Flood Resilience\nKey Lessons Learned\nRipple effects of an open data initiative for resilience\nTriggering a global collaborative network\n\nReferences\nWeb sites and software\n\nRamani Huria ProjectCommunity Mapping For Flood Resilience\n‚ÄúDar Ramani Huria‚Äù (Swahili for ‚ÄúDar Open Map‚Äù) is the name of a community-based mapping project in Dar es Salaam, Tanzania. This project brought together international agencies, local university students and community members with the aim of putting the city‚Äôs most flood- prone areas ‚Äúon the map‚Äù for the first time, an endeavor made possible by the coordinated adoption of a host of geospatial and open data tools. Dar es Salaam is one of the fastest growing cities in Africa, with an annual population growth of about 5%. Urbanization is largely unplanned and over half of city residents live in informal settlements. Every year during the rainy seasons, the coastal city endures floods and heavy rains that cause great damage and economic loss, even death. As is often the case, the poorest citizens living in informal areas suffer disproportionally from these hazardous events. Damaged roads and footpaths force business and services to close for days and, after flooding, unplanned settlements become more vulnerable to diseases such as cholera. Because of the city‚Äôs largely unregulated growth, available maps are highly inaccurate, which hampers both the immediate response attempts and adequate long-term planning to improve disaster preparedness. Dar Ramani Huria is a multi-partner collaboration facilitated by Tanzania‚Äôs 2011 commitment to the Open Government Partnership (OGP), an international initiative in which governments have pledged to become more open, accountable and responsive to citizens. Under the auspices of the Tanzania government, and in line with its new commitment to transparency and citizen engagement, the project is supported by the Tanzania Commission for Science and Technology (COSTECH), the World Bank‚Äôs Global Facility for Disaster Reduction and Recovery (GFDRR), and the Red Cross. The key operational responsibility lies with Humanitarian OpenStreetMap Team (HOT) and such local partners as municipal councils and planning agencies. Playing another fundamental role in giving legitimacy and stability to the project, two local universities (University of Dar es Salaam and Ardhi University) seized this opportunity to teach valuable geospatial analysis skills to students, who make up most of the mapping teams. Since January 2015, the project has covered 29 neighborhoods (locally known as wards) within four districts of Dar es Salaam, encompassing the most flood-prone areas of the city. The project operations follow these main steps: 1) Building on drone-generated Very High Resolution (VHR) imagery, mappers capture features like drainage lines, water and sanitation facilities, roads and footpaths, buildings and key landmarks. 2) The detailed data captured in the various wards through GPS devices are digitized using the OpenStreetMap platform. 3) Risk assessment is performed by InaSAFE software, an open-source tool piloted in Indonesia that is provided as a plugin for QGIS and enables users to run natural disaster scenarios for better impact assessment and response planning.\nKey Lessons Learned\nRipple effects of an open data initiative for resilience\nDuring a conversation about the project, two executives of Ramani Huria (Edward Anderson, Senior Disaster Risk Management Specialist at the World Bank, and Mark Iliffe, a geospatial expert) first remarked that from the outset the benefits of mapping started multiplying in areas of interventions beyond the original intended goals. The project website reports several interviews with Ward Executive Officers of the involved neighborhoods, illustrating how quickly they turned into the most enthusiastic advocates of the initiative ‚Äì most of them, the interviewer reported, proudly display printouts of the maps in the office. These local officials can now use the extremely accurate ward maps to present projects to the municipality, or to plan roads and drainage construction. Covered wards have also benefited from these maps in unexpected ways, such as promoting adhesion to the national addressing system, planning for better provision of services like health centers and schools, or directing the work of local NGOs. Such unintended effects of the initiative echo the very justification of open data, which is to make curated information accessible, understandable and usable for a broad array of users, potentially serving purposes unforeseen by the data creators. Furthermore, maps and data are now available for anyone interested in doing research or developing applications that can improve the livelihoods of citizens. Another fascinating aspect of the project, which extends beyond disaster response, is how well this approach to mapping matches the reality of a city growing at a fast pace in a mostly unplanned fashion. While lacking or outdated maps are often cited as one huge obstacle to systematic upgrading of urban informal areas, this community-mapping initiative (facilitated by the OSM platform) empowers the very residents of these communities ‚Äì who are both the experts and ultimate beneficiaries ‚Äì giving them a voice in the identification and prioritization of their actual needs. In a peculiar role switch, the data deficit caused by Dar‚Äôs inadequate institutional capacity is gradually being filled from the bottom up.\nTriggering a global collaborative network\nAs noted by Patrick Meier in a very thought-provoking talk on creating resilience through big data: ‚ÄúThe term resilience is important because it focuses not on the development and disaster response community, but rather on local at-risk communities‚Äù and their own coping mechanisms. Within the long-standing debate about the effectiveness (or lack thereof) of top- 4) Maps and underlying data collected within Ramani Huria are free and accessible for anyone on OpenStreetMap (OSM) and on the project website. As the project is rolled out in multiples wards, various technical workshops, kickoff events and ‚Äòmaphatons‚Äô are effectively keeping the communities engaged and promoting the dissemination of results in different forum. down approaches in development, Dar Ramani Huria is a remarkable example of how a broad array of involved parties can be successfully mobilized in a multi-polar scheme. Clearly, a complex partnership like Dar Ramani Huria benefited from a fortunate combination of enabling conditions, including the government‚Äôs timely commitment towards open data, the backing of universities and the political will of local officials. Nevertheless, the unprecedented growth of geospatial and analytical open-source software plays an indisputable ‚Äúcrowdsourcing‚Äù role. Nowadays, a highly complex issue such as improving resilience in unplanned urban areas can be tackled within a paradigm of distributed problem solving, where local civil society can join international geospatial experts and software designers to contribute to critical urban-planning decisions. Another interesting byproduct of open data is the creation of ‚Äúvirtual communities‚Äù that effectively connect people who would not seem associated by location or cultural proximity. A case in point is the InaSAFE tool for disaster risk analysis, initially designed in Indonesia, which was seamlessly combined with Ramani Huria-generated maps for flooding risk analysis. The desire to help when natural hazards hit (we are sadly witnessing stronger and more frequent earthquakes, floods and hurricanes all over the world) is probably a universal human reaction, particularly when such events strike close to home or we perceive a personal connection to the victims. Yet, our globalized and constantly connected world can leave us a sense of frustration when we struggle to identify an effective way to help or fail to see the fruits of our contribution. The multiplication of open access platforms (OpenStreetMaps, Ushahidi, WorldPop and the likes) and, to some extent, social media have this promising power to directly match people in need with individuals or groups that have the right skills to help. It is well documented how many digital volunteers and geospatial experts mobilized to help after the recent earthquakes in Haiti and Nepal, working together (remotely or in loco) contributing coding skills, updating web documents and maps, or simply posting tweets and photos to fill critical information gaps. While GIS and geospatial analysis still require a significant degree of technical skills for certain steps along the data pipeline, there are increasing opportunities for basic users to perform key data collection tasks, also owing to the huge role of mobile technology in bridging the digital divide. Certainly, open data does not mean ‚Äúunregulated,‚Äù and issues of security or privacy protection deserve adequate consideration at the international and local levels. Nonetheless Dar Ramani Huria is yet another demonstration of the undeniable potential of open-data platforms to effectively promote a transparent, collaborative and incremental creation of vital information to improve lives.\nReferences\nDavies, Tim. 2014. ‚ÄúOpen Data in Developing Countries ‚Äì Emerging insights from Phase I‚Äù. Web Foundation, Berlin.\nDeogawanka, Sangeeta. 2015, May 9. How Crowdsourced Mapping is Supporting Relief Efforts in Nepal [Blog post]. Retrieved from https://www.gislounge.com/how-crowdsourced- mapping-is-supporting-relief-efforts-in-nepal/ Humanitarian OpenStreetMap Team. 2015. ‚ÄúFlood Resilience in Dar es Salaam Second Quarterly Report‚Äù. HOT, Washington, DC.\nMeier, Patrick. 2013, January 11. How to Create Resilience Through Big Data [Blog post]. Retrieved from https://irevolutions.org/2013/01/11/disaster-resilience-2-0/\nUN Committee of Experts on Global Geospatial Information Management. 2015. ‚ÄúFuture trends in geospatial information management: the five to ten year vision‚Äù. UN-GGIM, New York.\nWeb sites and software\nRamani Huria (http://ramanihuria.org/) - Dar Ramani Huria project website providing description, access to data and news.\nInaSAFE (http://inasafe.org) - an extension for QGIS that allows disaster managers to do better contingency planning for disasters.\nOpenStreetMap (https://www.openstreetmap.org/) - The Free Wiki World Map ‚Äì An openly licensed map of the world being created by volunteers using local knowledge, GPS tracks and donated sources.\nQGIS (https://www.qgis.org/) - is a cross-platform free and open-source desktop geographic information system (GIS) application that provides data viewing, editing, and analysis.\nUshahidi (https://www.ushahidi.com/) - a non-profit software company that develops free and open-source software (LGPL) for information collection, visualisation, and interactive mapping.\nWorldPop (http://www.worldpop.org.uk/) - open platform for spatial demographic data\n\n\n\n",
    "preview": {},
    "last_modified": "2022-05-02T16:38:14+02:00",
    "input_file": {}
  },
  {
    "path": "posts/2009-02-21-sussidiar/",
    "title": "Sussidiariet√† e sviluppo: l‚Äôelettricit√† nelle favelas dell‚ÄôAmerica Latina",
    "description": {},
    "author": [],
    "date": "2009-02-21",
    "categories": [
      "ideas"
    ],
    "contents": "\n\nContents\nTre casi in Colombia e Brasile\nUna responsabilizzazione condivisa\nCreativit√† e realismo\nNote e indicazioni bibliografiche\n\n\nI prepared this blog post as a reflection on the experience as a graduate student and summer intern in a NGO working in Brazil\n\nBy Luisa M. Mimmi | View of Rio de JaneiroUno dei temi che hanno maggiormente animato il recente dibattito sulla cooperazione allo sviluppo √® la critica rivolta a governi e istituzioni multilaterali (Banca Mondiale, Fondo Monetario Internazionale e varie agenzie ONU in primis), di gestire gli aiuti ai paesi in via di sviluppo in modo arbitrario, assitenzialista e ultimamente inefficace (in sintesi con un approccio top-down). D‚Äôaltra parte, un numero crescente di voci, talvolta provenienti dal cuore stesso di queste istituzioni, come Bill Easterly 1 per citare uno dei pi√π rappresentativi, invocano un‚Äôazione multilaterale per lo sviluppo diversa, meno supponente e pi√π attenta alla realt√† vera di chi √® povero, in altre parole un approccio bottom-up. Provocatoriamente, ma forse saggiamente, Muhammad Yunus,2 il fondatore della Grameen Bank divenuto con il Nobel per la Pace l‚Äôicona internazionale del microcredito, suggeriva di trasferire la sede centrale della Banca Mondiale da Washington a un villaggio del Bangladesh, come antidoto all‚Äôapproccio burocratico e un po‚Äô altezzoso a volte riscontrato nei suoi funzionari. Ma tralasciando i dibattiti accademici, ci√≤ che emerge da alcune ricerche nell‚Äôambito dell‚Äôaccesso alle infrastrutture nei paesi emergenti dell‚ÄôAmerica Latina √® che, in realt√†, vi √® un fermento in atto di iniziative e programmi che sono davvero bottom-up, e c‚Äô√® un manipolo di persone che, in un dialogo che allaccia le capitali occidentali le favelas sudamericane, tentano con grande creativit√† di interagire in un modo che appare inequivocabilmente come una concreta applicazione del principio di sussidiariet√†. Quel che segue √® una sintetica illustrazione di alcuni casi, in cui il coinvolgimento attivo del settore privato e dei corpi intermedi della societ√† e delle comunit√† locali si √® rivelato la chiave per orientare e incanalare in modo efficace il sostegno pubblico allo sviluppo.\nTre casi in Colombia e Brasile\nIl primo caso √® quello dell‚Äôimpresa Codensa,3 la maggiore societ√† colombiana di distribuzione dell‚Äôenergia elettrica, che ridisegnando il proprio modello di business √® riuscita a conciliare il profitto con il servizio ai propri consumatori delle aree urbane povere di Bogot√†. Dopo la ristrutturazione del 1997, la societ√† si trovava a fronteggiare la recessione generale, aggravata dal terrorismo e dalle entrate incerte dovute a una clientela per la maggior parte composta da famiglie negli strati pi√π poveri della societ√†. Codensa ha optato per un modello improntato su due pilastri, la gestione efficiente della distribuzione di energia e la conoscenza approfondita della propria clientela. Dopo aver ridotto al minimo gli sprechi e le inefficienze, la societ√† si √® impegnata a incrementare i propri ricavi migliorando ed allargando il proprio portafoglio di servizi. L‚Äôintuizione fondamentale scaturiva dalla constatazione che pochissimi clienti disponevano di elettrodomestici, ragion per cui Codensa ha lanciato prestiti agevolati accordandosi con i principali produttori locali di elettrodomestici. Al contempo, si impegnava ad alzare la qualit√† della fornitura e degli allacciamenti dell‚Äôenergia elettrica. Adottando meccanismi ispirati al microcredito, Codensa ha quindi permesso a tanti suoi clienti che non avevano mai messo piede in banca di ottenere credito al consumo (spesso ancorando il pagamento delle rate alle proprie bollette elettriche). La risposta √® stata estremamente positiva, tanto che la societ√†, oltre all‚Äôelettricit√† ed agli elettrodomestici, adesso offre ai suoi clienti anche servizi assicurativi, di riparazione e ristrutturazione della casa, fino a servizi funebri ed altro. A chi sospetta la societ√† di aver sfruttato ai fini di profitto famiglie gi√† svantaggiate, rispondono i bilanci di Condensa che mostrano indici di soddisfazione per il servizio mai cos√¨ alti (soprattutto tra le fasce povere), ridotte percentuali di clienti indebitati o insolventi, e famiglie che dispongono di servizi finanziari prima inaccessibili (credito bancario, assicurazioni) e con tassi di restituzione del tutto soddisfacenti.\nVi sono poi i due casi gemelli dei progetti brasiliani ‚ÄúAgente‚Äù e ‚ÄúConviver‚Äù, facilitati dal lavoro della ONG italiana AVSI in stretta collaborazione con Coelba e CEMIG, le rispettive utilit√† dell‚Äôenergia a Salvador de Bahia e a Belo Horizonte. Le motivazioni all‚Äôorigine di tali interventi (avviati con considerevoli investimenti da parte delle due compagnie) erano problematiche simili legate all‚Äôaltissimo numero di famiglie povere residenti nelle favelas delle due metropoli brasiliane servite dalle rispettive compagnie. In particolare l‚Äô alta incidenza di connessioni illegali (‚Äúgatos‚Äù in brasiliano) e di clienti insolventi o indebitati, la scarsa qualit√† del servizio ed i conseguenti incidenti e insicurezza urbana. In tale contesto, il rapporto tra la compagnia elettrica e questi quartieri poveri era compromesso a tal punto che i tecnici (che ormai si presentavano quasi esclusivamente per tagliare i fili a chi non pagava pi√π) non potevano pi√π entrare in alcune strade per timore di rappresaglie violente. La risposta, pensata insieme ad AVSI, √® stata quella di partire dal ripristino delle relazioni tra azienda e clienti poveri attraverso un mezzo molto semplice e immediato. Un gruppo di giovani operatori (da cui appunto il nome ‚Äúprogetto agente‚Äù) 4, residenti nelle favelas stesse, sono stati selezionati e formati per andare a visitare le famiglie, casa per casa, e attraverso successive visite (di conoscenza, immatricolazione e poi operative) mettere in atto una serie di azioni che andavano dalla installazione di lampadine efficienti gratuite, alla rinegoziazione dei debiti con rate personalizzate, alla educazione al risparmio energetico finalizzato ad ottenere tariffe agevolate. Vale la pena soffermarsi su due aspetti particolarmente significativi di tali progetti. Il primo, ho potuto constatarlo di persona accompagnando alcuni di questi giovani agenti nei loro giri in una favela di Belo Horizonte. Ed √® la reazione prima stupita, e a volte quasi commossa di alcune persone nel ricevere la visita dei giovani operatori. Per alcuni si trattava di una cosa inaudita, per il fatto che questi giovani (esplicitamente preparati a presentarsi con discrezione, pazienza e rispetto) dedicassero del tempo ad ascoltare i loro problemi, a capire la loro situazione, e a valutare insieme una soluzione. La seconda sottolineatura √® emersa dall‚Äôanalisi approfondita del caso ‚ÄúConviver‚Äù di Belo Horizonte e dallo studio specifico delle tariffe sussidiate che in Brasile sono previste per i clienti residenziali con redditi bassi e che vengono attribuite in base a un duplice criterio di volumi di energia consumati e reddito.5 In pratica, tali tariffe sono disegnate in modo da crescere secondo un meccanismo a blocchi, garantendo sconti elevatissimi per il consumo di sussistenza, e poi via via decrescenti nei successivi blocchi di volume consumato. Evidentemente queste speciali tariffe, volte a garantire l‚Äôaccesso idealmente universale a servizi di base, rappresentano de facto un sussidio di povert√†. Pertanto, ha senso domandarsi se siano pi√π o meno efficaci delle tradizionali forme dirette di sussidio di povert√† (cash transfer), quali Bolsa Familia, che in Brasile rappresentano una politica caratterizzante della presidenza Lula. Gli esperti in materia generalmente accusano i sussidi ancorati alla quantita‚Äô consumata (in questo caso di energia) di essere assegnati in modo meno solidale dei sussidi diretti, ovvero di escludere un numero maggiore di veri poveri.6 Al contrario, dall‚Äôanalisi di un campione di oltre 15.000 famiglie di Belo Horizonte, risulta che tale ‚Äúerrore di esclusione‚Äù (la percentuale tra i pi√π poveri che non riceve il sussidio) √© enormemente maggiore nel caso del rinomato sussidio diretto alle famiglie Bolsa Familia 7, rispetto alle tariffe sociali basate sul consumo di energia. Certamente, tale significativo indicatore √® solo uno dei criteri che devono entrare nella valutazione dei trasferimenti pubblici e, del resto, la validit√† di una tale conclusione non pu√≤ essere generalizzata in modo superficiale. Ci√≤ nonostante, questo risultato mette in evidenza che, almeno in quel contesto specifico, il sussidio pi√π strettamente ancorato al consumo reale della famiglia di un bene di base (l‚Äôelettricit√†) si dimostra distribuito in modo pi√π giusto. Senza contare un‚Äôaltra fondamentale qualit√† dei sussidi energetici descritti, ovvero il connaturato incentivo al risparmio energetico. Di fatti, e l‚Äôinformazione in questo senso era parte integrante del progetto ‚ÄúConviver‚Äù, lo stesso meccanismo tariffario a blocchi, presuppone che a fronte di una maggiore accortezza ed efficienza nel consumo dell‚Äôenergia, una famiglia possa notevolmente abbassare la spesa energetica, con un annesso impatto ambientale positivo.\nUna responsabilizzazione condivisa\nQuesto ci porta ad una ulteriore considerazione su come valutare l‚Äôefficacia di un programma di sviluppo. In apparenza infatti si potrebbe pensare che, qualora un governo abbia mezzi e volont√† politica di ridistribuire fondi ai pi√π poveri, dei sussidi diretti e commisurati al reddito siano la strada in fondo pi√π opportuna. Ma torniamo per un attimo ai descritti programmi di elettrificazione delle favelas. Il valore aggiunto di tali programmi √© molto di pi√π che una semplice alternativa ad un approccio assistenziale di redistribuzione dei redditi. In questi casi, infatti, si osserva chiaramente la attiva responsabilizzazione di un gruppo variegato di agenti coinvolti, che √® bene scomporre pi√π nel dettaglio. Vi sono innanzitutto le compagnie elettriche coinvolte in tali progetti, tutte almeno parzialmente privatizzate nel corso della massiccia ondata di privatizzazioni in America Latina degli anni ‚Äô90. Esse dimostrano in modo evidente che, nonostante la cronaca recente porti a dubitarne, non c‚Äô√® incompatibilit√† tra una normale logica di profitto ed un‚Äôattivit√† con fine sociale. Infatti, specialmente in un‚Äôottica di lungo periodo, conviene all‚Äôazienda contribuire al miglioramento del benessere delle comunit√† in cui opera, in quanto proprio l√¨ risiedono i suoi potenziali clienti, fornitori e dipendenti, tutti soggetti vitali per la sua esistenza. I massicci investimenti versati dalle utilities negli esempi riferiti confermano questo. I nostri casi-esempio mettono poi in primo piano i clienti (nella fattispecie i consumatori pi√π poveri). Da pi√π parti nel pensiero di alcuni economisti (da Amartya Sen 8 con la sua idea seminale di ‚Äúbasic capabilities‚Äù, a C.K. Prahalad col suo paradigma della ‚ÄòBase della Piramide‚Äô9 , o lo stesso Yunus sul microcredito), si viene irrobustendo la corrente di pensiero secondo cui i soggetti degli strati pi√π poveri della popolazione non sono semplicemente passivi recettori di assistenza, ma bens√¨ attivi protagonisti di scelte, iniziative e tentativi di migliorare la propria condizione. Certo, per operare con loro, il business deve anche saper leggere i loro bisogni e differenziare l‚Äôofferta di prodotti e servizi secondo le specifiche esigenze e disponibilit√† finanziarie, ma i casi di successo di questo ‚Äòcapitalismo creativo‚Äô in aree povere si moltiplicano negli ambiti pi√π diversi, dai prodotti assicurativi, alla telefonia mobile ai beni di largo consumo. E‚Äô interessante poi sottolineare come, in tutti i recenti programmi pilota di elettrificazione delle favelas, la valutazione ex-post della soddisfazione dei clienti/beneficiari ricopre un ruolo chiave nel decidere della fattibilit√† e viabilit√† dei progetti stessi su larga scala.10 Infatti, nella maggioranza dei casi, la reale percezione di un migliore servizio e di una maggiore duttilit√† della compagnia nel riscuotere i pagamenti √® chiaramente la condizione perch√© tanti clienti prima illegali decidano di regolarizzarsi. Il che rappresenta il prerequisito necessario a garantire alla azienda fornitrice un flusso atteso di ricavi adeguato a coprire i costi iniziali dei programmi. E‚Äô altres√¨ interessante notare che i residenti delle favelas metropolitane di fatto ‚Äòdesiderano‚Äô regolarizzare i propri contratti di fornitura dei servizi. In Brasile ad esempio, nella condizione di precariet√† ed esclusione sociale che affligge tanti favelados, disporre di un indirizzo e di una regolare bolletta elettrica costituisce per alcuni un vero e proprio ‚Äòpassaporto per la cittadinanza‚Äô, in quanto prova sufficiente per aprire un conto in banca. Inoltre, non si pu√≤ certo tralasciare il ruolo chiave giocato da tutti quei corpi intermedi intervenuti nella realizzazione di questi progetti, quali le Organizzazioni Non Governative, alcune agenzie di sviluppo ed altre forme locali di rappresentanza dei quartieri poveri. Questi soggetti sono nella maggioranza dei casi il vero ponte di conoscenza e di dialogo tra le grandi aziende private e le comunit√† svantaggiate, presso cui essi sono in genere presenti e legittimati. Infine, lo stato, nelle sue espressioni nazionali e locali, potrebbe erroneamente sembrare il grande assente in queste operazioni, ma evidentemente non √® cosi. Certo, i casi descritti, e molti altri simili, si caratterizzano per un impulso iniziale di natura privata, ci√≤ nondimeno essi necessitano dell‚Äôintervento pubblico, e non in termini finanziari soltanto. Di fatto, anche laddove un‚Äôazienda decida di operare in una zona socialmente svantaggiata, esistono delle iniziali barriere di accesso che quasi sempre presuppongono qualche incentivo pubblico ad intervenire. Inoltre, in un quadro di reale sussidiariet√† in atto, anche allo stato √® chiesta la sua parte, ovvero garantire la stabilit√† macro-economica, politica e regolatoria, cos√¨ come la trasparenza nei processi competitivi e il rispetto dei contratti. Laddove queste condizioni non vengano assicurate (e l‚ÄôAmerica Latina ha purtroppo una pesante eredit√† politica di clientelismo e corruzione con cui fare i conti), √® chiaro che nessuna impresa privata pu√≤ ragionevolmente decidere di mettersi in gioco.\nCreativit√† e realismo\nUn altro aspetto affascinante di questi casi, oltre alla responsabilizzazione di diversi soggetti sopra descritta, √© la creativit√† e la notevole diversit√† degli approcci sperimentati. Se l‚Äôeconomia √® una disciplina che guarda all‚Äôuomo e ai suoi comportamenti, come tale dovrebbe sempre riflettere la costante tensione tra la semplificazione dei modelli - necessaria per intendere il reale - e la imprevedibilit√† ultima dell‚Äôagire umano. Vi sono anche altri recenti casi, sempre in contesti di povert√†, dove la fornitura di servizi di base (acqua, energia, telefonia) √© intrapresa da piccoli fornitori locali (Small Scale Providers) che in molti casi sono operatori informali. Tipicamente il servizio da loro fornito si configura, secondo una valutazione micro-economica, come un‚Äôopzione di second best (per via del costo marginale molto pi√π alto rispetto a quello di un tradizionale distributore su larga scala). Cio‚Äô nondimeno, ad esempio in certe aree rurali, questi piccoli fornitori informali sono l‚Äôunica risposta ad un bisogno che resterebbe altrimenti disatteso. L‚Äôofferta in termini di costo-qualit√† √® generalmente al di sotto dei nostri normali standard, ma risulta accettabile in quelle condizioni. Molto opportunamente, e ancora una volta secondo un approccio sussidiario, alcuni recenti progetti di cooperazione tendono a promuovere una valorizzazione di questi piccoli fornitori tramite meccanismi ad hoc mirati a sussidiarli parzialmente, anche allo scopo di abbattere il prezzo al consumo. Un chiaro esempio sono i cosiddetti sussidi ‚Äòperformance-based‚Äô, che, oltre ad essere generalmente attribuiti ai candidati fornitori tramite apposita asta competitiva, sono ancorati alla effettiva attuazione di determinati obiettivi pre-negoziati (come l‚Äôallacciamento di tot connessioni elettriche, o la depurazione di tot metri cubi di acqua potabile, ecc.). Anche in questi casi √® interessante sottolineare che tutto ci√≤ non scaturisce da una pianificazione a tavolino, ma bens√¨ da una valorizzazione di piccole e sporadiche realt√† in atto partite spontaneamente ‚Äòdalla base‚Äô come tentativi di risposta ad un bisogno percepito. Da ultimo, vale la pena osservare come il fiorire di iniziative come quelle riferite risulti particolarmente rilevante nella prospettiva della fase di crisi e di necessario ripensamento del sistema economico e produttivo a cui stiamo attualmente assistendo. Infatti, i casi esempio riportati colpiscono per l‚Äôevidente realismo con cui mirano a rendere universale l‚Äôaccesso e l‚Äôutilizzo di beni o servizi che sono generalmente concepiti come un legittimo diritto di tutti. C‚Äôe‚Äô infatti una marcata differenza tra queste iniziative (sorte dal basso) e altre politiche (decise politicamente) magari apparentemente valide, ma poi dimostratesi, alla prova dei fatti, insostenibili. Si pensi ad esempio al credito subprime, che, specialmente nelle intenzioni del partito democratico americano che lo ha energicamente promosso, mirava a garantire un diritto all‚Äôaccesso universale al credito, ma in qualche modo pretendendo di arrivarci snaturando il prodotto stesso e i suoi necessari requisiti (come la effettiva capacit√† di onorare il credito), oppure basandosi su condizioni (come gli altissimi tassi d‚Äôinteresse o le clausole punitive per la mora) del tutto sproporzionate rispetto alle effettive possibilit√† dei clienti destinatari. Diversamente, la validit√† di iniziative come quelle presentate, il loro realismo appunto, sta nel fatto che non aggirano i problemi oggettivi quali la criticit√† delle aree interessate, o la volatilit√† e insufficienza dei redditi delle famiglie beneficiate. Allo stesso tempo, tali iniziative rispettano la struttura e i requisiti fondamentali del mercato competitivo, come ad esempio la necessit√† di garantire un profitto ragionevole alle aziende private sostenibile nel tempo, o la diversificazione del prodotto/servizio in un modo adeguato alla tipologia del consumatore. In sostanza, a partire dall‚Äôosservazione attenta di problemi strutturali complessi, e delle specificit√† di ogni situazione locale, la caratteristica vincente dei programmi riferiti √® probabilmente il riuscire a sollecitare il necessario contributo di tutte le parti coinvolte nel trovare con creativit√† una soluzione. Forse oggi come mai, iniziative del genere vanno valorizzate e sostenute.\n\nLuisa Mimmi ha conseguito, nel 2008, un Master in ‚ÄúInternational Policy & Development‚Äù presso la Georgetown University. Attualmente lavora come consulente per la Inter-American Development Bank a Washington DC.\n\nNote e indicazioni bibliografiche\n\nWilliam Easterly √® stato Research Economist alla World Bank per 16 anni ed √® ora professore di economia alla NY University. E‚Äô noto al grande pubblico per il suo recente, molto dibattuto libro The White Man‚Äôs Burden (The Penguin Press, 2006).‚Ü©Ô∏é\nYunus, Muhammad and Alan Jolis. 2003. Banker to the Poor: Micro-Lending and the Battle Against World Poverty. Public Affairs.‚Ü©Ô∏é\nBueno, Manuel. December 7, 2007. ‚ÄúThe Codensa Case: Electricity and Related Services for the BOP in Colombia.‚Äù Articolo disponibile press oil sito web NextBillion.net - Development Through Enterprise. http://www.nextbillion.net/blogs/2007/12/07/the-codensa-case-electricity-and-related-services-for-the-bop-in-colombia‚Ü©Ô∏é\nPinhel, Antonio. 2005. ‚ÄúCoelba Agent Project.‚Äù Paper presentato al simposio del 2005 Slum Electrification Workshop promosso da Cities Alliance, Salvador de Bahia, Settembre 12-14. http://www.citiesalliance.org/publications/homepage-features/sept-05/slum-electrification-workshop.html‚Ü©Ô∏é\nMimmi, Luisa M. e Sencer Ecer. 2009. ‚ÄúIllegal electricity connections: main factors and impact of energy subsidies - A case study in the urban favelas of Belo Horizonte‚Äù [prossima pubblicazione].‚Ü©Ô∏é\nSul tema della assegnazione dei sussidi, vedere ad esempio i due significativi lavori di: Komives, Kristin, Jonathan Halpern, Vivien Foster, Quentin T. Wodon and Roohi Abdullah. 2006. ‚ÄúThe Distributional Incidence of Residential Water and Electricity Subsidies.‚Äù World Bank Policy Research Working Paper no. 3878. E anche: Coady, David, Margaret Grosh, and John Hoddinott. 2003. ‚ÄúThe Targeting of Transfers in Developing Countries: Review of Experience and Lessons.‚Äù Social Protection Discussion Paper, World Bank, Washington, DC.‚Ü©Ô∏é\nBolsa Fam√≠lia, fa parte dell‚Äôambizioso programma di welfare promosso dall‚Äôattuale governo federale brasiliano dal nome ‚ÄúFame zero‚Äù. Bolsa Fam√≠lia offre sostegno diretto alla famiglie povere ed indigenti a condizione che i bambini vadano a scuola e vengano vaccinati (segue cio√® il modello dei Conditional Cash Transfers). Il programma oggi raggiunge 11 milioni di famiglie e oltre 46 milioni di persone ed offre alle famiglie con figli un trasferimento mensile diretto medio di R$70 (circa US$35). Tale modello √® apparso oltre 10 anni fa in Brasile cos√¨ come altre iniziative oggi pi√π o meno convogliate in esso quali Bolsa Escola, Bolsa Gas, Carta del Cittadino ecc. Per quanto [^8]: risultati siano innegabilmente positivi in termini di raggiungimento e sostegno di famiglie svantaggiate, il programma ha anche alcune inevitabili criticit√†, quali la sostenibilit√† finanziaria, la possibilit√† di corruzione, e gli effetti distorsivi quali ad esempio il potenziale disincentivo al lavoro.‚Ü©Ô∏é\nSen, Amartya. 1980. ‚ÄúEquality of What?‚Äù in S. McMurrin, ed., Tanner Lectures on Human Values, Volume 1. Cambridge University Press, Cambridge. Reprinted in John Rawls et al.. 1987. Liberty,Equality and Law. Cambridge University Press, Cambridge.‚Ü©Ô∏é\nPrahalad, Coimbatore K. and Harvey C. Fruehauf. 2006. The fortune at the bottom of the pyramid: Eradicating Poverty Through Profit. Wharton School Publishing.‚Ü©Ô∏é\nI recenti case studies in Manzetti and Rufin (2006), Rojas and Lallement (2007), ESMAP (2007) confermano coerentemente il supporto alla adozione di politiche (tipicamente promosse dal settore privato) basate sull‚Äôofferta di un sensibile miglioramento della qualit√†, disponibilit√† e accessibilit√† del servizio entro un breve periodo. Questo approccio ultimamente produce rendimenti per la societ√† per mezzo della riduzione delle perdite non tecniche. Rojas, Juan Manuel, Lallement Dominique. 2007. ‚ÄúMeeting the Energy Needs of the Urban Poor ‚Äì Lessons from electrification practitioners.‚Äù ESMAP technical paper 118/07, Edited by ESMAP c/o Energy and Water Department, World Bank, Washington, DC. Manzetti, Luigi, Rufin Carlos. 2006. ‚ÄúPrivate utility Supply in a Hostile Environment ‚Äì The experience of Water, Sanitation and Electricity Distribution Utilities in Northern Colombia, the Dominican Republic and Ecuador.‚Äù (Reference No.¬†IFM-142) Edited by Inter-American Development Bank, Washington, DC. ESMAP c/o Energy and Water Department The World Bank Group. 2007. ‚ÄúMeeting the Energy Needs of the Urban Poor.‚Äù ESMAP technical paper 118/07, Washington, DC. Ed. ESMAP c/o Energy and Water Department The World Bank Group.‚Ü©Ô∏é\n",
    "preview": {},
    "last_modified": "2022-05-02T16:38:14+02:00",
    "input_file": {}
  }
]
